{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfa582f8",
   "metadata": {},
   "source": [
    "### 03 Estimator 이해 및 fit(), predict() 메서드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3786eb",
   "metadata": {},
   "source": [
    " 사이킷런은 API 일관성과 개발 편의성을 제공하기 위한 노력이 엿보이는 패키지이다. 사이킷런은 ML모델 학습을 위해서 fit()을, 학습된 모델의 예측을 위해 predict()메서드를 제공한다. 지도학습의 주요 두 축인 분류(Classification)와 회귀(Regression)의 다양한 알고리즘을 구현한 모든 사이킷런 클래스는 fit()과 predict()만을 이용해 간단하게 학습과 예측 결과를 반환한다. \n",
    "\n",
    "사이팃런에서는 분류 알고리즘을 구현한 클래스를 Classifier로, 그리고 회귀 알고리즘을 구현한 클래스를 Regressor 로 지칭한다. 이들 Classifier와 Regressor를 합쳐서 Estimator 클래스라고 부른다. 즉, 지도학습의 모든 알고리즘을 구현한 클래스를 통칭해서 Estimator라고 부른다.\n",
    "\n",
    "당연히 Estimator 클래스는 fit()과 predict()를 내부에서 구현하고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ec36fe",
   "metadata": {},
   "source": [
    "사이킷런에서 비지도학습인 차원 축소, 클러스터링, 피처 추출(Feature Extraction) 등을 구현한 클래스 역시 대부분 fit()과 transform()을 적용한다. 비지도학습과 피처 추출에서 fit()은 지도학습의 fit()과 같이 학습을 의미하는 것이 아니라 입력 데이터의 형태에 맞춰 데이터를 변환하기 위한 사전 구조를 맞추는 작업이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2893354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "print(type(iris_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef064df6",
   "metadata": {},
   "source": [
    "load_iris() API의 반환결과가 sklearn.utils.Bunch 클래스임을 의미함. Bunch클래스는 기초 파이썬의 딕셔너리 형태와 매우 유사하다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97f434ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트의 키들: dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "keys = iris_data.keys()\n",
    "print('붓꽃 데이터 세트의 키들:', keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27b7abb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " feature_names의 type: <class 'list'>\n",
      "\n",
      " feature_names의 shape: 4\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "\n",
      " target_names의 type: <class 'numpy.ndarray'>\n",
      "\n",
      " tatget_names의 shape: 3\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "\n",
      " target의 type: <class 'numpy.ndarray'>\n",
      "\n",
      " tatget의 shape: 150\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print('\\n feature_names의 type:', type(iris_data.feature_names))\n",
    "print('\\n feature_names의 shape:', len(iris_data.feature_names))\n",
    "print(iris_data.feature_names)\n",
    "\n",
    "print('\\n target_names의 type:', type(iris_data.target_names))\n",
    "print('\\n tatget_names의 shape:', len(iris_data.target_names))\n",
    "print(iris_data.target_names)\n",
    "\n",
    "print('\\n target의 type:', type(iris_data.target))\n",
    "print('\\n tatget의 shape:', len(iris_data.target))\n",
    "print(iris_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a7ba179",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85d9c682",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier()\n",
    "iris_data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a8372ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target,\\\n",
    "                                                   test_size=0.3, random_state=121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1566eb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "249cd87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도:0.9556\n"
     ]
    }
   ],
   "source": [
    "dt_clf.fit(X_train, y_train)\n",
    "pred = dt_clf.predict(X_test)\n",
    "print('예측 정확도:{0:.4f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a91edda",
   "metadata": {},
   "source": [
    "#### 교차 검증\n",
    "\n",
    "앞서 알고리즘을 학습시키는 학습데이터와 이에 대한 예측 성능을 평가하기 위한 별도의 테스트용 데이터가 필요하다고 하였다(hold_out). 하지만 이 방법 역시 과적합(overfitting)에 취약한 약점을 가질 수 있다.\n",
    "\n",
    "\n",
    "* 과적합이란 모델이 학습 데이터에만 과도하게 최적화되어, 실제 예측을 다른 데이터로 수행할 경우에는 예측 성능이 과도하게 떨어지는 것을 말한다. \n",
    "\n",
    "\n",
    "그런데 고정된 학습 데이터와 테스트 데이터로 평가를 하다보면 테스트 데이터에만 최적의 성능을 발휘할 수 있도록 편향되게 모델을 유도하는 경향이 생기게 된다. 이러한 문제점을 개선하기 위해 교차 검증을 이용해 더 다양한 학습과 평가를 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa7cce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3453eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트 크기: 150\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "features = iris.data #x값\n",
    "label = iris.target #y값\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "#5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성.\n",
    "Kfold = KFold(n_splits=5)\n",
    "print('붓꽃 데이터 세트 크기:', features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc19f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
